{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-classification problem\n",
    "\n",
    "__Note:__ you might need to do\n",
    "`conda install torchvision \"pillow<7\"`\n",
    "if torchvision is not already installed on your computer, and/or for compatibility issues (the version of torchvision version supporting the last version of Pillow is not released yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USPS Dataset\n",
    "* Handwritten digits with 10 classes\n",
    "* 16x16 pixels for each image \n",
    "* 6 000 data examples in training set, 1 291 examples in validation set, 2 007 in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6579383"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.bz2'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "if not os.path.isdir('USPS/'):\n",
    "    os.mkdir('USPS/')\n",
    "open('USPS/usps.bz2', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading USPS dataset from torchvision.dataset\n",
    "dataset = torchvision.datasets.USPS(root='USPS/',\n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset to training and validation sets\n",
    "train_set, val_set = random_split(dataset, [6000, 1291])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'image label: 9')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_index = 88\n",
    "\n",
    "plt.imshow(dataset.data[sample_index], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.title(\"image label: %d\" % dataset.targets[sample_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.c1 = nn.Conv2d(1,6, 5, padding=2) # Convolution kernel 6 layer size 5, stride 1\n",
    "        self.c2 = nn.Conv2d(6,16, 5, padding = 2) # Convolution kernel 16 layer size 5, stride 1\n",
    "        self.l1 = nn.Linear(16 * 16 * 16, 120)\n",
    "        self.l2 = nn.Linear(120, 84)\n",
    "        self.l3 = nn.Linear(84, 10)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        h1 = F.relu(self.c1(inputs))\n",
    "        h2 = F.relu(self.c2(h1))\n",
    "        h3 = F.relu(self.l1(h2.view(h2.shape[0],-1)))\n",
    "        h4 = F.relu(self.l2(h3))\n",
    "        outputs = F.softmax(self.l3(h4), dim=1)# Use softmax as the activation function for the last layer\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model: \n",
    "model = Model()\n",
    "\n",
    "# Choose the hyperparameters for training: \n",
    "num_epochs = 60\n",
    "batch_size = 10\n",
    "\n",
    "# Use mean squared loss function \n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Use SGD optimizer with a learning rate of 0.01\n",
    "# It is initialized on our model\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for training\n",
    "def train(num_epochs, batch_size, criterion, optimizer, model, dataset):\n",
    "    train_error = []\n",
    "    train_loader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_average_loss = 0.0\n",
    "        for (images, labels) in train_loader:\n",
    "            #y_pre = model(images.view(batch_size, -1))\n",
    "            y_pre = model( images)\n",
    "            #reshape the inputs from [N, img_shape, img_shape] to [N, img_shape*img_shape] \n",
    "            \n",
    "            # One-hot encoding or labels so as to calculate MSE error:\n",
    "            labels_one_hot = torch.FloatTensor(batch_size, 10)\n",
    "            labels_one_hot.zero_()\n",
    "            labels_one_hot.scatter_(1, labels.view(-1, 1), 1)\n",
    "           \n",
    "            \n",
    "            loss = criterion(y_pre, labels_one_hot)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_average_loss += loss.item() * batch_size / len(dataset)\n",
    "        train_error.append(epoch_average_loss)\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, epoch_average_loss))\n",
    "    return train_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Loss: 0.0898\n",
      "Epoch [2/60], Loss: 0.0888\n",
      "Epoch [3/60], Loss: 0.0587\n",
      "Epoch [4/60], Loss: 0.0201\n",
      "Epoch [5/60], Loss: 0.0138\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-0464c72c26ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-9afb8b308cd0>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(num_epochs, batch_size, criterion, optimizer, model, dataset)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_one_hot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mepoch_average_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_error = train(num_epochs, batch_size, criterion, optimizer, model, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Visualization of convergence')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training error wrt. the number of epochs: \n",
    "plt.plot(range(1, num_epochs+1), train_error)\n",
    "plt.xlabel(\"num_epochs\")\n",
    "plt.ylabel(\"Train error\")\n",
    "plt.title(\"Visualization of convergence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy to evaluate the model\n",
    "def accuracy(dataset, model):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        dataloader = DataLoader(dataset)\n",
    "        for images, labels in dataloader:\n",
    "            #images = images.view(-1, 16*16)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1) \n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy of the model : {:.2f} %'.format(100*correct.item()/ len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model : 97.52 %\n"
     ]
    }
   ],
   "source": [
    "accuracy(val_set, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight 6 1 5 5, but got 3-dimensional input of size [1, 16, 16] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-12f71325919a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0moutout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#output = model(image.view(-1, 16*16))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-70a2ca8a3682>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mh1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mh3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 6 1 5 5, but got 3-dimensional input of size [1, 16, 16] instead"
     ]
    }
   ],
   "source": [
    "val_index = 66\n",
    "\n",
    "(image, label) = val_set[val_index]\n",
    "outout = model( image )\n",
    "#output = model(image.view(-1, 16*16))\n",
    "_, prediction = torch.max(output.data, 1)\n",
    "\n",
    "plt.imshow(image.view(16, 16), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.title(\"Prediction label: %d\" % prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Impact of the architecture of the model\n",
    "Define your own class `Model` to improve the predictions:\n",
    "\n",
    "* The convolutional layer can be a good choice to deal with images. Replace nn.Linear with [nn.Conv2d](https://pytorch.org/docs/stable/nn.html#conv2d).\n",
    "* Try to add more layers (1, 2, 3, more ?)\n",
    "* Change the number of neurons in hidden layers (5, 10, 20, more ?)\n",
    "* Try different activation functions such as [sigmoid](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.sigmoid), [tanh](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.tanh), [relu](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.relu), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Impact of the optimizer\n",
    "Retrain the model by using different parameters of the optimizer; you can change its parameters in the cell initializing it, after the definition of your model.\n",
    "\n",
    "* Use different batch sizes, from 10 to 1 000 for instance\n",
    "* Try different values of the learning rate (between 0.001 and 10), and see how these impact the training process. Do all network architectures react the same way to different learning rates?\n",
    "* Change the duration of the training by increasing the number of epochs\n",
    "* Try other optimizers, such as [Adam](https://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adam) or [RMSprop](https://pytorch.org/docs/stable/optim.html?highlight=rmsprop#torch.optim.RMSprop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Impact of the loss function\n",
    "The MSE error is rarely used in this case. The cross entropy loss can be a better choice for multi-classification problems. In pytorch, the cross entropy loss is defined by [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html#crossentropyloss). Replace the MSE loss by this one to observe its impact.\n",
    "\n",
    "**Note:** In order to use nn.CrossEntropyLoss correctly, don't add an activation function to the last layer of your network. And one-hot encoding is no longer needed to calculate the loss, delete the encoding procedures in function `train`.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Prediction on test set\n",
    "\n",
    "Once you have a model that seems satisfying on the validation dataset, you SHOULD evaluate it on a test dataset that has never been used before, to obtain a final accuracy value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1831726"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.t.bz2'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('USPS/usps.t.bz2', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading MNIST test set from torchvision.dataset\n",
    "test_set = torchvision.datasets.USPS(root='USPS/',\n",
    "                                         train=False,\n",
    "                                         transform=transforms.ToTensor(),\n",
    "                                         download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model : 93.42 %\n"
     ]
    }
   ],
   "source": [
    "accuracy(test_set, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
